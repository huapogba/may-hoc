{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d56119-cabb-4790-9802-6faed3cdb3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9412f8",
   "metadata": {},
   "source": [
    "## 1. Hàm tiền xử lí dữ liệu ảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47167cc0-c49d-4811-92d7-59731f982953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(\n",
    "    path, target_size=96, median_kernel_size=5, adaptive_block_size=17, adaptive_C=5\n",
    "):\n",
    "    if adaptive_block_size % 2 == 0 or adaptive_block_size < 3:\n",
    "        adaptive_block_size = max(3, adaptive_block_size + 1)\n",
    "        print(f\"Adjusted adaptive_block_size to {adaptive_block_size} (must be odd)\")\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        return None\n",
    "\n",
    "    img = cv2.medianBlur(cv2.resize(img, (256, 256)), median_kernel_size)\n",
    "    binary = cv2.adaptiveThreshold(\n",
    "        img,\n",
    "        255,  # Use gray_filtered here\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        adaptive_block_size,\n",
    "        adaptive_C,\n",
    "    )\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 50]\n",
    "    if not contours:\n",
    "        return None\n",
    "    cnt = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    digit = binary[y : y + h, x : x + w]\n",
    "\n",
    "    size_max = max(w, h)\n",
    "    square = np.zeros((size_max, size_max), dtype=np.uint8)\n",
    "    x_offset = (size_max - w) // 2\n",
    "    y_offset = (size_max - h) // 2\n",
    "    square[y_offset : y_offset + h, x_offset : x_offset + w] = digit\n",
    "\n",
    "    resized = cv2.resize(\n",
    "        square, (target_size, target_size), interpolation=cv2.INTER_AREA\n",
    "    )\n",
    "    normalized = resized.astype(\"float32\") / 255.0\n",
    "    normalized = normalized.reshape(target_size, target_size, 1)\n",
    "    return np.expand_dims(normalized, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a67bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = preprocess_image(\"../dataset/raw_dataset/0/005949_0_3982.JPG\")\n",
    "# img_np = img.squeeze()\n",
    "# plt.figure(figsize=(3, 3))\n",
    "# plt.subplot(1, 1, 1)\n",
    "# plt.imshow(img_np, cmap='gray')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83979eac",
   "metadata": {},
   "source": [
    "## 2. Class custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae6e40c-7473-454e-8e33-ac9915ac1239",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, target_size=96):\n",
    "        self.valid_data = []\n",
    "        for path, label in zip(image_paths, labels):\n",
    "            img = preprocess_image(path, target_size)\n",
    "            if img is not None:\n",
    "                self.valid_data.append((img, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.valid_data[idx]\n",
    "        img_tensor = (\n",
    "            torch.tensor(img, dtype=torch.float32).permute(0, 3, 1, 2).squeeze(0)\n",
    "        )\n",
    "        return img_tensor, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e25112d",
   "metadata": {},
   "source": [
    "## 3. Hàm load dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af1dff-c970-4a9f-af87-648013029278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_paths_and_labels(root_dir):\n",
    "    image_paths, labels = [], []\n",
    "    for label in os.listdir(root_dir):\n",
    "        label_path = os.path.join(root_dir, label)\n",
    "        if not os.path.isdir(label_path):\n",
    "            continue\n",
    "        for filename in os.listdir(label_path):\n",
    "            if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                image_paths.append(os.path.join(label_path, filename))\n",
    "                labels.append(int(label))\n",
    "    return image_paths, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a06bac",
   "metadata": {},
   "source": [
    "## 4. Hàm hiển thị ảnh mẫu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9968cc3c-7aa8-4e29-8002-5ce811e10e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_first_n_images(dataset, n=5):\n",
    "    plt.figure(figsize=(10, n))\n",
    "    for i in range(n):\n",
    "        img_tensor, label = dataset[i]\n",
    "        img_np = img_tensor.squeeze().numpy()\n",
    "        plt.subplot(n, 10, i + 1)\n",
    "        plt.imshow(img_np, cmap=\"gray\")\n",
    "        plt.title(f\"Label: {label}\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9facf437",
   "metadata": {},
   "source": [
    "## 5. Hàm train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc81d1c0-ac49-41b4-b937-92c9f815ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Train loss: {total_loss / len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23881051",
   "metadata": {},
   "source": [
    "## 6. Hàm test độ chính xác (acc) của model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9323e9e4-7a7c-4441-b015-3b875a8112c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Test loss: {total_loss / len(loader):.4f} - Accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35f17e4",
   "metadata": {},
   "source": [
    "## 7. Hàm dự đoán ảnh chữ viết tay từ thư mục tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400bb6a4-32d7-4224-bffb-20fa6f4c3fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_digits_from_folder(\n",
    "    model, input_folder, output_csv, device=\"cpu\", target_size=96\n",
    "):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    i = 1\n",
    "    for filename in os.listdir(input_folder):\n",
    "        print(i)\n",
    "        i += 1\n",
    "        if not filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            print(f\"⚠️ Ảnh không được hỗ trợ: {filename}. Random kết quả.\")\n",
    "            results.append([filename, random.randint(0, 9)])\n",
    "            continue\n",
    "        path = os.path.join(input_folder, filename)\n",
    "        img = preprocess_image(path, target_size)\n",
    "        if img is None:\n",
    "            print(f\"⚠️ Ảnh lỗi: {filename}. Random kết quả.\")\n",
    "            results.append([filename, random.randint(0, 9)])\n",
    "            continue\n",
    "        img_tensor = (\n",
    "            torch.tensor(img, dtype=torch.float32).permute(0, 3, 1, 2).to(device)\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor)\n",
    "            pred = output.argmax(dim=1).item()\n",
    "        results.append([filename, pred])\n",
    "    pd.DataFrame(results, columns=[\"filename\", \"predicted_label\"]).to_csv(\n",
    "        output_csv, index=False\n",
    "    )\n",
    "    print(f\"✅ Ghi kết quả vào: {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9acae58",
   "metadata": {},
   "source": [
    "## 8. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc74437",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SET_DIR = \"../dataset/train_set\"\n",
    "TEST_SET_DIR = \"../dataset/test_set\"\n",
    "OUTPUT_CSV = \"../pred.csv\"\n",
    "EPOCH = 20\n",
    "TARGET_SIZE = 192"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177e1a61",
   "metadata": {},
   "source": [
    "## 9. Chạy chương trình"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc973245",
   "metadata": {},
   "source": [
    "### 9.1. Load dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a6bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load và chia dữ liệuuuuu\n",
    "image_paths, labels = load_image_paths_and_labels(TRAIN_SET_DIR)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(image_paths, labels, test_size=0.1, stratify=labels, random_state=42)\n",
    "\n",
    "# Tạo Dataset\n",
    "train_dataset = CustomDataset(image_paths, labels, target_size=TARGET_SIZE)\n",
    "# test_dataset = CustomDataset(x_test, y_test, target_size=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e09a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiển thị n ânh mẫu đầu tiên\n",
    "show_first_n_images(train_dataset, n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ece79d",
   "metadata": {},
   "source": [
    "### 9.2. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969f41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "# Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18 = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, 10)\n",
    "model = resnet18.to(device)\n",
    "\n",
    "# Optimizer & Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train và Test\n",
    "for epoch in range(EPOCH):\n",
    "    print(f\"\\nEpoch {epoch + 1}\")\n",
    "    train(model, train_loader, criterion, optimizer, device)\n",
    "    # test(model, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cb1739",
   "metadata": {},
   "source": [
    "### 9.3. Dự đoán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a964a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_digits_from_folder(\n",
    "    model, TEST_SET_DIR, OUTPUT_CSV, device=device, target_size=TARGET_SIZE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
